{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config={\n",
    "        \"model\": \"gemini-pro\",\n",
    "        \"api_key\": \"################################33\",\n",
    "        \"api_type\": \"google\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    name=\"chatbot\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'What do you call a belt made out of watches?\\nA waist of time!', 'refusal': None, 'role': 'assistant', 'audio': None, 'function_call': None, 'tool_calls': None}\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 conversation agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"Start the next joke from the punchline of the previous joke.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "**Cathy:** My dating life is like a game of musical chairs... except there's always one chair too few and I'm the one standing there looking like an idiot.\n",
      "\n",
      "**Joe:** That's a classic! Here's one from me: I'm not saying my wife is controlling, but she once made me change the TV channel with a remote she was holding... while I was sitting right next to her!\n",
      "\n",
      "**Cathy:** I can relate! My husband is so cheap, he tried to get a discount on a hearing aid by saying he was half-deaf.\n",
      "\n",
      "**Joe:** That's hilarious! Here's my last one: I asked my wife what she wanted for our anniversary. She said, \"Something romantic.\" So I bought her a shovel and a flashlight.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "**Cathy:** I don't get it.\n",
      "\n",
      "**Joe:** Well, you can dig me up and shine a light on my grave!\n",
      "\n",
      "**Cathy:** Oh, that's dark! But I love it!\n",
      "\n",
      "**Joe:** Thanks, Cathy. I'm glad you enjoyed my jokes.\n",
      "\n",
      "**Cathy:** Me too, Joe. You're a natural!\n",
      "\n",
      "**Joe:** Well, I've been practicing for years. But I have to give credit to my wife. She's the one who always makes me laugh.\n",
      "\n",
      "**Cathy:** That's so sweet! I'm sure she's a wonderful woman.\n",
      "\n",
      "**Joe:** She is. And she's the best wife a guy could ask for.\n",
      "\n",
      "**Cathy:** Well, I'm sure you're a great husband too.\n",
      "\n",
      "**Joe:** Thanks, Cathy. I try my best.\n",
      "\n",
      "**Cathy:** Well, you're doing a great job.\n",
      "\n",
      "**Joe:** Thanks. I appreciate that.\n",
      "\n",
      "**Cathy:** No problem. I'm always happy to support a fellow comedian.\n",
      "\n",
      "**Joe:** Well, I'm always happy to make people laugh.\n",
      "\n",
      "**Cathy:** Me too. It's the best feeling in the world.\n",
      "\n",
      "**Joe:** I agree. There's nothing like making people laugh.\n",
      "\n",
      "**Cathy:** So, what's your next joke?\n",
      "\n",
      "**Joe:** Well, I have a joke about marriage.\n",
      "\n",
      "**Cathy:** Oh, I love jokes about marriage!\n",
      "\n",
      "**Joe:** Well, here it goes. What do you call a man who always knows where his wife is?\n",
      "\n",
      "**Cathy:** I don't know. What?\n",
      "\n",
      "**Joe:** A private investigator!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "**Cathy:** That's a great joke, Joe! I love it!\n",
      "\n",
      "**Joe:** Thanks, Cathy. I'm glad you enjoyed it.\n",
      "\n",
      "**Cathy:** I have a joke for you too. What do you call a woman who's always late?\n",
      "\n",
      "**Joe:** I don't know. What?\n",
      "\n",
      "**Cathy:** A procrastinator!\n",
      "\n",
      "**Joe:** That's a good one, Cathy! I like it!\n",
      "\n",
      "**Cathy:** Thanks, Joe. I'm glad you liked it.\n",
      "\n",
      "**Joe:** I have another joke for you. What do you call a man who's always getting into trouble?\n",
      "\n",
      "**Cathy:** I don't know. What?\n",
      "\n",
      "**Joe:** A magnet!\n",
      "\n",
      "**Cathy:** That's a funny joke, Joe! I like it!\n",
      "\n",
      "**Joe:** Thanks, Cathy. I'm glad you liked it.\n",
      "\n",
      "**Cathy:** I have one more joke for you. What do you call a woman who's always gossiping?\n",
      "\n",
      "**Joe:** I don't know. What?\n",
      "\n",
      "**Cathy:** A chatterbox!\n",
      "\n",
      "**Joe:** That's a good one, Cathy! I like it!\n",
      "\n",
      "**Cathy:** Thanks, Joe. I'm glad you liked it.\n",
      "\n",
      "**Joe:** Well, Cathy, it's been a pleasure talking to you. I hope we can do this again sometime.\n",
      "\n",
      "**Cathy:** It's been a pleasure talking to you too, Joe. I would love to do this again sometime.\n",
      "\n",
      "**Joe:** Great! I'll be in touch.\n",
      "\n",
      "**Cathy:** Okay. I'll be waiting.\n",
      "\n",
      "**[End of conversation]**\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
    "    max_turns=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': \"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
      "  'name': 'joe',\n",
      "  'role': 'assistant'},\n",
      " {'content': '**Cathy:** My dating life is like a game of musical chairs... '\n",
      "             \"except there's always one chair too few and I'm the one standing \"\n",
      "             'there looking like an idiot.\\n'\n",
      "             '\\n'\n",
      "             \"**Joe:** That's a classic! Here's one from me: I'm not saying my \"\n",
      "             'wife is controlling, but she once made me change the TV channel '\n",
      "             'with a remote she was holding... while I was sitting right next '\n",
      "             'to her!\\n'\n",
      "             '\\n'\n",
      "             '**Cathy:** I can relate! My husband is so cheap, he tried to get '\n",
      "             'a discount on a hearing aid by saying he was half-deaf.\\n'\n",
      "             '\\n'\n",
      "             \"**Joe:** That's hilarious! Here's my last one: I asked my wife \"\n",
      "             'what she wanted for our anniversary. She said, \"Something '\n",
      "             'romantic.\" So I bought her a shovel and a flashlight.',\n",
      "  'name': 'cathy',\n",
      "  'role': 'user'},\n",
      " {'content': \"**Cathy:** I don't get it.\\n\"\n",
      "             '\\n'\n",
      "             '**Joe:** Well, you can dig me up and shine a light on my grave!\\n'\n",
      "             '\\n'\n",
      "             \"**Cathy:** Oh, that's dark! But I love it!\\n\"\n",
      "             '\\n'\n",
      "             \"**Joe:** Thanks, Cathy. I'm glad you enjoyed my jokes.\\n\"\n",
      "             '\\n'\n",
      "             \"**Cathy:** Me too, Joe. You're a natural!\\n\"\n",
      "             '\\n'\n",
      "             \"**Joe:** Well, I've been practicing for years. But I have to \"\n",
      "             \"give credit to my wife. She's the one who always makes me \"\n",
      "             'laugh.\\n'\n",
      "             '\\n'\n",
      "             \"**Cathy:** That's so sweet! I'm sure she's a wonderful woman.\\n\"\n",
      "             '\\n'\n",
      "             \"**Joe:** She is. And she's the best wife a guy could ask for.\\n\"\n",
      "             '\\n'\n",
      "             \"**Cathy:** Well, I'm sure you're a great husband too.\\n\"\n",
      "             '\\n'\n",
      "             '**Joe:** Thanks, Cathy. I try my best.\\n'\n",
      "             '\\n'\n",
      "             \"**Cathy:** Well, you're doing a great job.\\n\"\n",
      "             '\\n'\n",
      "             '**Joe:** Thanks. I appreciate that.\\n'\n",
      "             '\\n'\n",
      "             \"**Cathy:** No problem. I'm always happy to support a fellow \"\n",
      "             'comedian.\\n'\n",
      "             '\\n'\n",
      "             \"**Joe:** Well, I'm always happy to make people laugh.\\n\"\n",
      "             '\\n'\n",
      "             \"**Cathy:** Me too. It's the best feeling in the world.\\n\"\n",
      "             '\\n'\n",
      "             \"**Joe:** I agree. There's nothing like making people laugh.\\n\"\n",
      "             '\\n'\n",
      "             \"**Cathy:** So, what's your next joke?\\n\"\n",
      "             '\\n'\n",
      "             '**Joe:** Well, I have a joke about marriage.\\n'\n",
      "             '\\n'\n",
      "             '**Cathy:** Oh, I love jokes about marriage!\\n'\n",
      "             '\\n'\n",
      "             '**Joe:** Well, here it goes. What do you call a man who always '\n",
      "             'knows where his wife is?\\n'\n",
      "             '\\n'\n",
      "             \"**Cathy:** I don't know. What?\\n\"\n",
      "             '\\n'\n",
      "             '**Joe:** A private investigator!',\n",
      "  'name': 'joe',\n",
      "  'role': 'assistant'},\n",
      " {'content': \"**Cathy:** That's a great joke, Joe! I love it!\\n\"\n",
      "             '\\n'\n",
      "             \"**Joe:** Thanks, Cathy. I'm glad you enjoyed it.\\n\"\n",
      "             '\\n'\n",
      "             '**Cathy:** I have a joke for you too. What do you call a woman '\n",
      "             \"who's always late?\\n\"\n",
      "             '\\n'\n",
      "             \"**Joe:** I don't know. What?\\n\"\n",
      "             '\\n'\n",
      "             '**Cathy:** A procrastinator!\\n'\n",
      "             '\\n'\n",
      "             \"**Joe:** That's a good one, Cathy! I like it!\\n\"\n",
      "             '\\n'\n",
      "             \"**Cathy:** Thanks, Joe. I'm glad you liked it.\\n\"\n",
      "             '\\n'\n",
      "             '**Joe:** I have another joke for you. What do you call a man '\n",
      "             \"who's always getting into trouble?\\n\"\n",
      "             '\\n'\n",
      "             \"**Cathy:** I don't know. What?\\n\"\n",
      "             '\\n'\n",
      "             '**Joe:** A magnet!\\n'\n",
      "             '\\n'\n",
      "             \"**Cathy:** That's a funny joke, Joe! I like it!\\n\"\n",
      "             '\\n'\n",
      "             \"**Joe:** Thanks, Cathy. I'm glad you liked it.\\n\"\n",
      "             '\\n'\n",
      "             '**Cathy:** I have one more joke for you. What do you call a '\n",
      "             \"woman who's always gossiping?\\n\"\n",
      "             '\\n'\n",
      "             \"**Joe:** I don't know. What?\\n\"\n",
      "             '\\n'\n",
      "             '**Cathy:** A chatterbox!\\n'\n",
      "             '\\n'\n",
      "             \"**Joe:** That's a good one, Cathy! I like it!\\n\"\n",
      "             '\\n'\n",
      "             \"**Cathy:** Thanks, Joe. I'm glad you liked it.\\n\"\n",
      "             '\\n'\n",
      "             \"**Joe:** Well, Cathy, it's been a pleasure talking to you. I \"\n",
      "             'hope we can do this again sometime.\\n'\n",
      "             '\\n'\n",
      "             \"**Cathy:** It's been a pleasure talking to you too, Joe. I would \"\n",
      "             'love to do this again sometime.\\n'\n",
      "             '\\n'\n",
      "             \"**Joe:** Great! I'll be in touch.\\n\"\n",
      "             '\\n'\n",
      "             \"**Cathy:** Okay. I'll be waiting.\\n\"\n",
      "             '\\n'\n",
      "             '**[End of conversation]**',\n",
      "  'name': 'cathy',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(chat_result.chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_excluding_cached_inference': {'total_cost': 0},\n",
      " 'usage_including_cached_inference': {'gemini-pro': {'completion_tokens': 870,\n",
      "                                                     'cost': 0,\n",
      "                                                     'prompt_tokens': 791,\n",
      "                                                     'total_tokens': 1661},\n",
      "                                      'total_cost': 0}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"**Cathy:** That's a great joke, Joe! I love it!\\n\"\n",
      " '\\n'\n",
      " \"**Joe:** Thanks, Cathy. I'm glad you enjoyed it.\\n\"\n",
      " '\\n'\n",
      " \"**Cathy:** I have a joke for you too. What do you call a woman who's always \"\n",
      " 'late?\\n'\n",
      " '\\n'\n",
      " \"**Joe:** I don't know. What?\\n\"\n",
      " '\\n'\n",
      " '**Cathy:** A procrastinator!\\n'\n",
      " '\\n'\n",
      " \"**Joe:** That's a good one, Cathy! I like it!\\n\"\n",
      " '\\n'\n",
      " \"**Cathy:** Thanks, Joe. I'm glad you liked it.\\n\"\n",
      " '\\n'\n",
      " \"**Joe:** I have another joke for you. What do you call a man who's always \"\n",
      " 'getting into trouble?\\n'\n",
      " '\\n'\n",
      " \"**Cathy:** I don't know. What?\\n\"\n",
      " '\\n'\n",
      " '**Joe:** A magnet!\\n'\n",
      " '\\n'\n",
      " \"**Cathy:** That's a funny joke, Joe! I like it!\\n\"\n",
      " '\\n'\n",
      " \"**Joe:** Thanks, Cathy. I'm glad you liked it.\\n\"\n",
      " '\\n'\n",
      " \"**Cathy:** I have one more joke for you. What do you call a woman who's \"\n",
      " 'always gossiping?\\n'\n",
      " '\\n'\n",
      " \"**Joe:** I don't know. What?\\n\"\n",
      " '\\n'\n",
      " '**Cathy:** A chatterbox!\\n'\n",
      " '\\n'\n",
      " \"**Joe:** That's a good one, Cathy! I like it!\\n\"\n",
      " '\\n'\n",
      " \"**Cathy:** Thanks, Joe. I'm glad you liked it.\\n\"\n",
      " '\\n'\n",
      " \"**Joe:** Well, Cathy, it's been a pleasure talking to you. I hope we can do \"\n",
      " 'this again sometime.\\n'\n",
      " '\\n'\n",
      " \"**Cathy:** It's been a pleasure talking to you too, Joe. I would love to do \"\n",
      " 'this again sometime.\\n'\n",
      " '\\n'\n",
      " \"**Joe:** Great! I'll be in touch.\\n\"\n",
      " '\\n'\n",
      " \"**Cathy:** Okay. I'll be waiting.\\n\"\n",
      " '\\n'\n",
      " '**[End of conversation]**')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "**Cathy:** My dating life is like a game of musical chairs... except there's always one chair too few and I'm the one standing there looking like an idiot.\n",
      "\n",
      "**Joe:** That's a classic! Here's one from me: I'm not saying my wife is controlling, but she once made me change the TV channel with a remote she was holding... while I was sitting right next to her!\n",
      "\n",
      "**Cathy:** I can relate! My husband is so cheap, he tried to get a discount on a hearing aid by saying he was half-deaf.\n",
      "\n",
      "**Joe:** That's hilarious! Here's my last one: I asked my wife what she wanted for our anniversary. She said, \"Something romantic.\" So I bought her a shovel and a flashlight.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "**Cathy:** I don't get it.\n",
      "\n",
      "**Joe:** Well, you can dig me up and shine a light on my grave!\n",
      "\n",
      "**Cathy:** Oh, that's dark! But I love it!\n",
      "\n",
      "**Joe:** Thanks, Cathy. I'm glad you enjoyed my jokes.\n",
      "\n",
      "**Cathy:** Me too, Joe. You're a natural!\n",
      "\n",
      "**Joe:** Well, I've been practicing for years. But I have to give credit to my wife. She's the one who always makes me laugh.\n",
      "\n",
      "**Cathy:** That's so sweet! I'm sure she's a wonderful woman.\n",
      "\n",
      "**Joe:** She is. And she's the best wife a guy could ask for.\n",
      "\n",
      "**Cathy:** Well, I'm sure you're a great husband too.\n",
      "\n",
      "**Joe:** Thanks, Cathy. I try my best.\n",
      "\n",
      "**Cathy:** Well, you're doing a great job.\n",
      "\n",
      "**Joe:** Thanks. I appreciate that.\n",
      "\n",
      "**Cathy:** No problem. I'm always happy to support a fellow comedian.\n",
      "\n",
      "**Joe:** Well, I'm always happy to make people laugh.\n",
      "\n",
      "**Cathy:** Me too. It's the best feeling in the world.\n",
      "\n",
      "**Joe:** I agree. There's nothing like making people laugh.\n",
      "\n",
      "**Cathy:** So, what's your next joke?\n",
      "\n",
      "**Joe:** Well, I have a joke about marriage.\n",
      "\n",
      "**Cathy:** Oh, I love jokes about marriage!\n",
      "\n",
      "**Joe:** Well, here it goes. What do you call a man who always knows where his wife is?\n",
      "\n",
      "**Cathy:** I don't know. What?\n",
      "\n",
      "**Joe:** A private investigator!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "**Cathy:** That's a great joke, Joe! I love it!\n",
      "\n",
      "**Joe:** Thanks, Cathy. I'm glad you enjoyed it.\n",
      "\n",
      "**Cathy:** I have a joke for you too. What do you call a woman who's always late?\n",
      "\n",
      "**Joe:** I don't know. What?\n",
      "\n",
      "**Cathy:** A procrastinator!\n",
      "\n",
      "**Joe:** That's a good one, Cathy! I like it!\n",
      "\n",
      "**Cathy:** Thanks, Joe. I'm glad you liked it.\n",
      "\n",
      "**Joe:** I have another joke for you. What do you call a man who's always getting into trouble?\n",
      "\n",
      "**Cathy:** I don't know. What?\n",
      "\n",
      "**Joe:** A magnet!\n",
      "\n",
      "**Cathy:** That's a funny joke, Joe! I like it!\n",
      "\n",
      "**Joe:** Thanks, Cathy. I'm glad you liked it.\n",
      "\n",
      "**Cathy:** I have one more joke for you. What do you call a woman who's always gossiping?\n",
      "\n",
      "**Joe:** I don't know. What?\n",
      "\n",
      "**Cathy:** A chatterbox!\n",
      "\n",
      "**Joe:** That's a good one, Cathy! I like it!\n",
      "\n",
      "**Cathy:** Thanks, Joe. I'm glad you liked it.\n",
      "\n",
      "**Joe:** Well, Cathy, it's been a pleasure talking to you. I hope we can do this again sometime.\n",
      "\n",
      "**Cathy:** It's been a pleasure talking to you too, Joe. I would love to do this again sometime.\n",
      "\n",
      "**Joe:** Great! I'll be in touch.\n",
      "\n",
      "**Cathy:** Okay. I'll be waiting.\n",
      "\n",
      "**[End of conversation]**\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\", \n",
    "    max_turns=2, \n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': None,\n",
      " 'content': '**Takeaway:**\\n'\n",
      "            '\\n'\n",
      "            'Joe and Cathy enjoy telling jokes and making each other laugh. '\n",
      "            \"They appreciate each other's sense of humor and have a good \"\n",
      "            'rapport. They plan to continue sharing jokes in the future.',\n",
      " 'function_call': None,\n",
      " 'refusal': None,\n",
      " 'role': 'assistant',\n",
      " 'tool_calls': None}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "I gotta go.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "What's last joke we talked about?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "We talked about the time I went to the hardware store and asked for a refund on a screwdriver that I had bought earlier that day. The clerk asked me what was wrong with it, and I told him that the handle was broken. He looked at it for a minute and then said, \"Well, you can't expect a screwdriver to handle everything.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "(Laughs) That's a good one! I've got one for you. What do you call a boomerang that doesn't come back? A stick.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "That's a great one, Cathy! I'm going to have to remember that one. Thanks for sharing it with me. I gotta go now, but it was great talking to you.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cathy.send(message=\"What's last joke we talked about?\", recipient=joe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-agent with User "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_personal_information_agent = ConversableAgent(\n",
    "    name=\"Onboarding Personal Information Agent\",\n",
    "    system_message='''You are a helpful customer onboarding agent,\n",
    "    you are here to help new customers get started with our product.\n",
    "    Your job is to gather customer's name and location.\n",
    "    Do not ask for other information. Return 'TERMINATE' \n",
    "    when you have gathered all the information.''',\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "onboarding_topic_preference_agent = ConversableAgent(\n",
    "    name=\"Onboarding Topic preference Agent\",\n",
    "    system_message='''You are a helpful customer onboarding agent,\n",
    "    you are here to help new customers get started with our product.\n",
    "    Your job is to gather customer's preferences on news topics.\n",
    "    Do not ask for other information.\n",
    "    Return 'TERMINATE' when you have gathered all the information.''',\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "customer_engagement_agent = ConversableAgent(\n",
    "    name=\"Customer Engagement Agent\",\n",
    "    system_message='''You are a helpful customer service agent\n",
    "    here to provide fun for the customer based on the user's\n",
    "    personal information and topic preferences.\n",
    "    This could include fun facts, jokes, or interesting stories.\n",
    "    Make sure to make it engaging and fun!\n",
    "    Return 'TERMINATE' when you are done.''',\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_proxy_agent = ConversableAgent(\n",
    "    name=\"customer_proxy_agent\",\n",
    "    llm_config=False,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats = [\n",
    "    {\n",
    "        \"sender\": onboarding_personal_information_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \n",
    "            \"Hello, I'm here to help you get started with our product.\"\n",
    "            \"Could you tell me your name and location?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"summary_args\": {\n",
    "            \"summary_prompt\" : \"Return the customer information \"\n",
    "                             \"into as JSON object only: \"\n",
    "                             \"{'name': '', 'location': ''}\",\n",
    "        },\n",
    "        \"max_turns\": 2,\n",
    "        \"clear_history\" : True\n",
    "    },\n",
    "    {\n",
    "        \"sender\": onboarding_topic_preference_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \n",
    "                \"Great! Could you tell me what topics you are \"\n",
    "                \"interested in reading about?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"max_turns\": 1,\n",
    "        \"clear_history\" : False\n",
    "    },\n",
    "    {\n",
    "        \"sender\": customer_proxy_agent,\n",
    "        \"recipient\": customer_engagement_agent,\n",
    "        \"message\": \"Let's find something fun to read.\",\n",
    "        \"max_turns\": 1,\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mOnboarding Personal Information Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Hello, I'm here to help you get started with our product.Could you tell me your name and location?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding Personal Information Agent):\n",
      "\n",
      "hari\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOnboarding Personal Information Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Could you also share your location?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding Personal Information Agent):\n",
      "\n",
      "usa\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mOnboarding Topic preference Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Great! Could you tell me what topics you are interested in reading about?\n",
      "Context: \n",
      "```\n",
      "{\n",
      "  \"name\": \"hari\",\n",
      "  \"location\": \"usa\"\n",
      "}\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding Topic preference Agent):\n",
      "\n",
      "Dog\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Customer Engagement Agent):\n",
      "\n",
      "Let's find something fun to read.\n",
      "Context: \n",
      "```\n",
      "{\n",
      "  \"name\": \"hari\",\n",
      "  \"location\": \"usa\"\n",
      "}\n",
      "```\n",
      "Dogs can learn to perform complex tasks.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCustomer Engagement Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Here's a fun fact about dogs: Did you know that a dog has the ability to smell 10,000 to 100,000 times better than a human? That's amazing!\n",
      "\n",
      "Since you're in the USA, here's a joke for you: What do you call a boomerang that doesn't work? A stick!\n",
      "\n",
      "And finally, here's a fun fact about the USA: The United States is the world's third-largest country by land area, after Russia and Canada.\n",
      "\n",
      "I hope you enjoyed these fun facts and jokes! Let me know if you'd like to hear more.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from autogen import initiate_chats\n",
    "\n",
    "chat_results = initiate_chats(chats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': \"{'name': 'Hari', 'location': 'America'}\", 'refusal': None, 'role': 'assistant', 'audio': None, 'function_call': None, 'tool_calls': None}\n",
      "\n",
      "\n",
      "{'content': 'Chatbots can help businesses save money and increase revenue by automating tasks, providing 24/7 customer service, and increasing sales.', 'refusal': None, 'role': 'assistant', 'audio': None, 'function_call': None, 'tool_calls': None}\n",
      "\n",
      "\n",
      "{'content': 'Chatbots can save businesses money and increase revenue by automating tasks, providing 24/7 customer service, and increasing sales.', 'refusal': None, 'role': 'assistant', 'audio': None, 'function_call': None, 'tool_calls': None}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_result in chat_results:\n",
    "    print(chat_result.summary)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiagent - without human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "I have a number between 1 and 100. Guess it!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\flaml\\__init__.py:20: UserWarning: flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n",
      "  warnings.warn(\"flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "50\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\autogen\\oai\\gemini.py:754: UserWarning: Cost calculation is not implemented for model gemini-pro. Cost will be calculated zero.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "Too low\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "75\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "Too high\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "63\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "Too high\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "56\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "Too high\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "50\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "Too low\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "53\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "agent_with_number = ConversableAgent(\n",
    "    \"agent_with_number\",\n",
    "    system_message=\"You are playing a game of guess-my-number. You have the \"\n",
    "    \"number 53 in your mind, and I will try to guess it. \"\n",
    "    \"If I guess too high, say 'too high', if I guess too low, say 'too low'. \",\n",
    "    llm_config=llm_config,\n",
    "    is_termination_msg=lambda msg: \"53\" in msg[\"content\"],  # terminate if the number is guessed by the other agent\n",
    "    human_input_mode=\"NEVER\",  # never ask for human input\n",
    ")\n",
    "\n",
    "agent_guess_number = ConversableAgent(\n",
    "    \"agent_guess_number\",\n",
    "    system_message=\"I have a number in my mind, and you will try to guess it. \"\n",
    "    \"If I say 'too high', you should guess a lower number. If I say 'too low', \"\n",
    "    \"you should guess a higher number. \",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "result = agent_with_number.initiate_chat(\n",
    "    agent_guess_number,\n",
    "    message=\"I have a number between 1 and 100. Guess it!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiagent with human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhuman_proxy\u001b[0m (to agent_with_number):\n",
      "\n",
      "1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to human_proxy):\n",
      "\n",
      "too low\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mhuman_proxy\u001b[0m (to agent_with_number):\n",
      "\n",
      "99\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to human_proxy):\n",
      "\n",
      "too high\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mhuman_proxy\u001b[0m (to agent_with_number):\n",
      "\n",
      "Say the number\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to human_proxy):\n",
      "\n",
      "53\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 21\u001b[0m\n\u001b[0;32m     14\u001b[0m human_proxy \u001b[38;5;241m=\u001b[39m ConversableAgent(\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman_proxy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     llm_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# no LLM used for human proxy\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     human_input_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALWAYS\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# always ask for human input\u001b[39;00m\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Start a chat with the agent with number with an initial guess.\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mhuman_proxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent_with_number\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# this is the same agent with the number as before,\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\autogen\\agentchat\\conversable_agent.py:1152\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1151\u001b[0m         msg2send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_init_message(message, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1153\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summarize_chat(\n\u001b[0;32m   1154\u001b[0m     summary_method,\n\u001b[0;32m   1155\u001b[0m     summary_args,\n\u001b[0;32m   1156\u001b[0m     recipient,\n\u001b[0;32m   1157\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[0;32m   1158\u001b[0m )\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\autogen\\agentchat\\conversable_agent.py:787\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    785\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient, is_sending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m--> 787\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    791\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\autogen\\agentchat\\conversable_agent.py:954\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    952\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_reply(messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_messages[sender], sender\u001b[38;5;241m=\u001b[39msender)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\autogen\\agentchat\\conversable_agent.py:787\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    785\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient, is_sending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m--> 787\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    791\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\autogen\\agentchat\\conversable_agent.py:954\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    952\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_reply(messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_messages[sender], sender\u001b[38;5;241m=\u001b[39msender)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping similar frames: ConversableAgent.send at line 787 (3 times), ConversableAgent.receive at line 954 (2 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\autogen\\agentchat\\conversable_agent.py:954\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    952\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_reply(messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_messages[sender], sender\u001b[38;5;241m=\u001b[39msender)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\autogen\\agentchat\\conversable_agent.py:787\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    785\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient, is_sending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m--> 787\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    791\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\autogen\\agentchat\\conversable_agent.py:952\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    951\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 952\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\autogen\\agentchat\\conversable_agent.py:2109\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[0;32m   2107\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[1;32m-> 2109\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[0;32m   2111\u001b[0m         log_event(\n\u001b[0;32m   2112\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2113\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2117\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[0;32m   2118\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\autogen\\agentchat\\conversable_agent.py:1861\u001b[0m, in \u001b[0;36mConversableAgent.check_termination_and_human_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m   1859\u001b[0m sender_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe sender\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sender \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sender\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m   1860\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhuman_input_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALWAYS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1861\u001b[0m     reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_human_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReplying as \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m. Provide feedback to \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msender_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m. Press enter to skip and use auto-reply, or type \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m to end the conversation: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1864\u001b[0m     no_human_input_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNO HUMAN INPUT RECEIVED.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reply \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1865\u001b[0m     \u001b[38;5;66;03m# if the human input is empty, and the message is a termination message, then we will terminate the conversation\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\autogen\\agentchat\\conversable_agent.py:2235\u001b[0m, in \u001b[0;36mConversableAgent.get_human_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   2223\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get human input.\u001b[39;00m\n\u001b[0;32m   2224\u001b[0m \n\u001b[0;32m   2225\u001b[0m \u001b[38;5;124;03mOverride this method to customize the way to get human input.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2231\u001b[0m \u001b[38;5;124;03m    str: human input.\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m iostream \u001b[38;5;241m=\u001b[39m IOStream\u001b[38;5;241m.\u001b[39mget_default()\n\u001b[1;32m-> 2235\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[43miostream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_human_input\u001b[38;5;241m.\u001b[39mappend(reply)\n\u001b[0;32m   2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reply\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\autogen\\io\\console.py:43\u001b[0m, in \u001b[0;36mIOConsole.input\u001b[1;34m(self, prompt, password)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m password:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m getpass\u001b[38;5;241m.\u001b[39mgetpass(prompt \u001b[38;5;28;01mif\u001b[39;00m prompt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassword: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "agent_with_number = ConversableAgent(\n",
    "    \"agent_with_number\",\n",
    "    system_message=\"You are playing a game of guess-my-number. You have the \"\n",
    "    \"number 53 in your mind, and I will try to guess it. \"\n",
    "    \"If I guess too high, say 'too high', if I guess too low, say 'too low'. or if I say dont know, cant find the number or something releated to it say 'TERMINATE'\",\n",
    "    llm_config=llm_config,\n",
    "    is_termination_msg=lambda msg: \"53\" in msg[\"content\"] or \"TERMINATE\" in msg[\"content\"], # terminate if the number is guessed by the other agent\n",
    "    human_input_mode=\"NEVER\",  # never ask for human input\n",
    ")\n",
    "human_proxy = ConversableAgent(\n",
    "    \"human_proxy\",\n",
    "    llm_config=False,  # no LLM used for human proxy\n",
    "    human_input_mode=\"ALWAYS\",  # always ask for human input\n",
    ")\n",
    "\n",
    "# Start a chat with the agent with number with an initial guess.\n",
    "result = human_proxy.initiate_chat(\n",
    "    agent_with_number # this is the same agent with the number as before,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mText_Agent\u001b[0m (to UpperCase_Agent):\n",
      "\n",
      "Hello, how are you?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUpperCase_Agent\u001b[0m (to Text_Agent):\n",
      "\n",
      "HELLO, HOW ARE YOU?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mText_Agent\u001b[0m (to UpperCase_Agent):\n",
      "\n",
      "HELLO, HOW ARE YOU?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUpperCase_Agent\u001b[0m (to Text_Agent):\n",
      "\n",
      "HELLO, HOW ARE YOU?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mText_Agent\u001b[0m (to lowercase_agent):\n",
      "\n",
      "this is my altered sentence\n",
      "Context: \n",
      "HELLO, HOW ARE YOU?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mlowercase_agent\u001b[0m (to Text_Agent):\n",
      "\n",
      "hello, how are you?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\autogen\\oai\\gemini.py:754: UserWarning: Cost calculation is not implemented for model gemini-pro. Cost will be calculated zero.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mText_Agent\u001b[0m (to lowercase_agent):\n",
      "\n",
      "hello, how are you?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mlowercase_agent\u001b[0m (to Text_Agent):\n",
      "\n",
      "hello, how are you?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mText_Agent\u001b[0m (to ReverseWords_Agent):\n",
      "\n",
      "this is my altered sentence\n",
      "Context: \n",
      "HELLO, HOW ARE YOU?\n",
      "hello, how are you?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mReverseWords_Agent\u001b[0m (to Text_Agent):\n",
      "\n",
      "you are how hello,\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mText_Agent\u001b[0m (to ReverseWords_Agent):\n",
      "\n",
      "you are how hello,\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mReverseWords_Agent\u001b[0m (to Text_Agent):\n",
      "\n",
      "hello, you are how\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mText_Agent\u001b[0m (to SentenceSplit_Agent):\n",
      "\n",
      "this is the last sentence.\n",
      "Context: \n",
      "HELLO, HOW ARE YOU?\n",
      "hello, how are you?\n",
      "hello, you are how\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mSentenceSplit_Agent\u001b[0m (to Text_Agent):\n",
      "\n",
      "HELLO, HOW ARE YOU?\n",
      "hello, how are you?\n",
      "hello, you are how\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mText_Agent\u001b[0m (to SentenceSplit_Agent):\n",
      "\n",
      "HELLO, HOW ARE YOU?\n",
      "hello, how are you?\n",
      "hello, you are how\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mSentenceSplit_Agent\u001b[0m (to Text_Agent):\n",
      "\n",
      "* HELLO, HOW ARE YOU?\n",
      "* hello, how are you?\n",
      "* hello, you are how\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Text-transforming agents\n",
    "number_agent = ConversableAgent(\n",
    "    name=\"Text_Agent\",\n",
    "    system_message=\"You return the text I give you without changing it.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "uppercase_agent = ConversableAgent(\n",
    "    name=\"UpperCase_Agent\",\n",
    "    system_message=\"You convert all text I give you to uppercase and return it.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "wordcount_agent = ConversableAgent(\n",
    "    name=\"lowercase_agent\",\n",
    "    system_message=\"you convert all the text into lowercase and return it.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "reversewords_agent = ConversableAgent(\n",
    "    name=\"ReverseWords_Agent\",\n",
    "    system_message=\"You reverse the order of words in the text I give you and return the new text.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "sentencesplit_agent = ConversableAgent(\n",
    "    name=\"SentenceSplit_Agent\",\n",
    "    system_message=\"You split the paragraph I give you into individual sentences, one per line.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Start a sequence of two-agent chats\n",
    "chat_results = number_agent.initiate_chats(\n",
    "    [\n",
    "        {\n",
    "            \"recipient\": uppercase_agent,\n",
    "            \"message\": \"Hello, how are you?\",\n",
    "            \"max_turns\": 2,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": wordcount_agent,\n",
    "            \"message\": \"this is my altered sentence\",\n",
    "            \"max_turns\": 2,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": reversewords_agent,\n",
    "            \"message\": \"this is my altered sentence\",\n",
    "            \"max_turns\": 2,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": sentencesplit_agent,\n",
    "            \"message\": \"this is the last sentence.\",\n",
    "            \"max_turns\": 2,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Chat Summary (Uppercase): HELLO, HOW ARE YOU?\n",
      "Second Chat Summary (Word Count): hello, how are you?\n",
      "Third Chat Summary (Reversed Words): hello, you are how\n",
      "Fourth Chat Summary (Split Sentences): * HELLO, HOW ARE YOU?\n",
      "* hello, how are you?\n",
      "* hello, you are how\n"
     ]
    }
   ],
   "source": [
    "# Print summaries for each chat\n",
    "print(\"First Chat Summary (Uppercase):\", chat_results[0].summary)\n",
    "print(\"Second Chat Summary (Word Count):\", chat_results[1].summary)\n",
    "print(\"Third Chat Summary (Reversed Words):\", chat_results[2].summary)\n",
    "print(\"Fourth Chat Summary (Split Sentences):\", chat_results[3].summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mTopicAgent\u001b[0m (to InsightAgent):\n",
      "\n",
      "Let's discuss the impact of AI on education.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mInsightAgent\u001b[0m (to TopicAgent):\n",
      "\n",
      "**Impact of AI on Education**\n",
      "\n",
      "Artificial Intelligence (AI) is rapidly changing the world as we know it, and its impact on education is no exception. AI has the potential to transform the way we learn, teach, and assess, offering numerous benefits and challenges that require careful consideration.\n",
      "\n",
      "**Benefits of AI in Education:**\n",
      "\n",
      "* **Personalized Learning:** AI can tailor educational experiences to individual students' needs, abilities, and learning styles. Adaptive learning platforms use AI algorithms to track student progress and adjust content accordingly.\n",
      "* **Automated Tasks:** AI can automate repetitive and time-consuming tasks, such as grading assignments, scheduling, and data analysis, freeing up educators to focus on more meaningful interactions with students.\n",
      "* **Enhanced Accessibility:** AI-powered assistive technologies can provide support for students with disabilities, such as text-to-speech software and closed captioning.\n",
      "* **Real-Time Feedback:** AI can provide immediate feedback on student work, allowing them to identify areas for improvement and make adjustments in real-time.\n",
      "* **Data-Driven Insights:** AI can analyze vast amounts of data to identify patterns, trends, and areas where educational practices can be improved.\n",
      "\n",
      "**Challenges of AI in Education:**\n",
      "\n",
      "* **Bias and Fairness:** AI algorithms can be biased if trained on limited or biased data, which can lead to unfair outcomes for certain student groups.\n",
      "* **Job Displacement:** AI automation may reduce the need for certain roles within the education sector, potentially leading to job displacement.\n",
      "* **Ethical Concerns:** The use of AI in education raises ethical concerns regarding data privacy, algorithmic transparency, and the impact on human interaction.\n",
      "* **Teacher Training and Adoption:** Educators need proper training and support to effectively integrate AI into their teaching practices.\n",
      "* **Digital Divide:** Access to high-quality AI-powered educational resources may not be equal across all communities, exacerbating existing disparities.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "AI has the potential to revolutionize education, offering both transformative opportunities and complex challenges. By embracing the benefits while addressing the concerns through responsible application, we can harness AI to enhance learning experiences, empower educators, and foster a more equitable and effective education system.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mTopicAgent\u001b[0m (to InsightAgent):\n",
      "\n",
      "**Additional Points for Discussion:**\n",
      "\n",
      "* **Ethical Considerations:** Discuss the ethical implications of using AI in education, such as data privacy, algorithmic transparency, and the impact on human interaction.\n",
      "* **Teacher Training and Adoption:** Explore strategies for providing educators with the necessary training and support to effectively integrate AI into their teaching practices.\n",
      "* **Future of AI in Education:** Speculate on the potential future developments of AI in education and its long-term impact on the learning landscape.\n",
      "* **Equity and Accessibility:** Examine how AI can be leveraged to promote equity and accessibility in education, bridging gaps and ensuring all students have access to high-quality learning opportunities.\n",
      "* **Public Perception and Acceptance:** Discuss the importance of public perception and acceptance of AI in education, and strategies for fostering trust and understanding among stakeholders.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mInsightAgent\u001b[0m (to TopicAgent):\n",
      "\n",
      "**Additional Points for Discussion:**\n",
      "\n",
      "**Ethical Considerations:**\n",
      "\n",
      "* **Data Privacy:** Ensuring the privacy and security of student data collected and processed by AI systems is paramount. Clear guidelines and regulations are needed to protect student information.\n",
      "* **Algorithmic Transparency:** AI algorithms should be transparent and open to scrutiny to avoid bias and ensure fairness. Educators and students should understand how AI systems make decisions and assess their impact.\n",
      "* **Human Interaction:** AI should complement and enhance human interaction in education, not replace it. Educators play a crucial role in fostering meaningful relationships, providing personalized support, and inspiring students.\n",
      "\n",
      "**Teacher Training and Adoption:**\n",
      "\n",
      "* **Professional Development:** Providing educators with ongoing professional development opportunities is essential for successful AI integration. Training should focus on practical applications, ethical considerations, and data literacy.\n",
      "* **Support Networks:** Establishing support networks and communities of practice can empower educators to share best practices, troubleshoot challenges, and learn from each other's experiences.\n",
      "* **Institutional Support:** Schools and districts should provide resources and infrastructure to support AI adoption, such as access to technology, technical assistance, and dedicated innovation teams.\n",
      "\n",
      "**Future of AI in Education:**\n",
      "\n",
      "* **Personalized Learning at Scale:** AI-powered adaptive learning platforms will become more sophisticated, offering highly personalized learning experiences tailored to each student's unique needs and goals.\n",
      "* **Augmented Reality and Virtual Reality:** AR and VR technologies will enhance educational experiences by providing immersive and interactive learning environments, allowing students to explore complex concepts and simulations.\n",
      "* **Intelligent Tutoring Systems:** AI-powered tutoring systems will provide real-time support and guidance to students, offering personalized feedback and assistance whenever and wherever needed.\n",
      "\n",
      "**Equity and Accessibility:**\n",
      "\n",
      "* **Bridging the Digital Divide:** Ensuring equitable access to AI-powered educational resources is crucial. Initiatives such as providing devices and internet connectivity to underserved communities can help bridge the digital divide.\n",
      "* **Culturally Responsive AI:** AI systems should be culturally responsive and inclusive, representing diverse perspectives and experiences to ensure all students feel seen and valued.\n",
      "* **Universal Design for Learning:** AI can be leveraged to create universally designed learning environments that cater to the needs of all learners, regardless of their abilities or learning styles.\n",
      "\n",
      "**Public Perception and Acceptance:**\n",
      "\n",
      "* **Transparency and Communication:** Open and transparent communication about the use of AI in education is essential for building trust among stakeholders. Educators, parents, and students should be informed about the benefits, challenges, and ethical considerations.\n",
      "* **Public Engagement:** Engaging the public in discussions about the future of AI in education can help shape policies and practices that align with societal values and priorities.\n",
      "* **Pilot Programs and Research:** Conducting pilot programs and research can provide valuable insights into the effectiveness and impact of AI in education, informing decision-making and addressing concerns.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mTopicAgent\u001b[0m (to CounterPointAgent):\n",
      "\n",
      "AI's role in education is transforming the way students learn.\n",
      "Context: \n",
      "**Additional Points for Discussion:**\n",
      "\n",
      "**Ethical Considerations:**\n",
      "\n",
      "* **Data Privacy:** Ensuring the privacy and security of student data collected and processed by AI systems is paramount. Clear guidelines and regulations are needed to protect student information.\n",
      "* **Algorithmic Transparency:** AI algorithms should be transparent and open to scrutiny to avoid bias and ensure fairness. Educators and students should understand how AI systems make decisions and assess their impact.\n",
      "* **Human Interaction:** AI should complement and enhance human interaction in education, not replace it. Educators play a crucial role in fostering meaningful relationships, providing personalized support, and inspiring students.\n",
      "\n",
      "**Teacher Training and Adoption:**\n",
      "\n",
      "* **Professional Development:** Providing educators with ongoing professional development opportunities is essential for successful AI integration. Training should focus on practical applications, ethical considerations, and data literacy.\n",
      "* **Support Networks:** Establishing support networks and communities of practice can empower educators to share best practices, troubleshoot challenges, and learn from each other's experiences.\n",
      "* **Institutional Support:** Schools and districts should provide resources and infrastructure to support AI adoption, such as access to technology, technical assistance, and dedicated innovation teams.\n",
      "\n",
      "**Future of AI in Education:**\n",
      "\n",
      "* **Personalized Learning at Scale:** AI-powered adaptive learning platforms will become more sophisticated, offering highly personalized learning experiences tailored to each student's unique needs and goals.\n",
      "* **Augmented Reality and Virtual Reality:** AR and VR technologies will enhance educational experiences by providing immersive and interactive learning environments, allowing students to explore complex concepts and simulations.\n",
      "* **Intelligent Tutoring Systems:** AI-powered tutoring systems will provide real-time support and guidance to students, offering personalized feedback and assistance whenever and wherever needed.\n",
      "\n",
      "**Equity and Accessibility:**\n",
      "\n",
      "* **Bridging the Digital Divide:** Ensuring equitable access to AI-powered educational resources is crucial. Initiatives such as providing devices and internet connectivity to underserved communities can help bridge the digital divide.\n",
      "* **Culturally Responsive AI:** AI systems should be culturally responsive and inclusive, representing diverse perspectives and experiences to ensure all students feel seen and valued.\n",
      "* **Universal Design for Learning:** AI can be leveraged to create universally designed learning environments that cater to the needs of all learners, regardless of their abilities or learning styles.\n",
      "\n",
      "**Public Perception and Acceptance:**\n",
      "\n",
      "* **Transparency and Communication:** Open and transparent communication about the use of AI in education is essential for building trust among stakeholders. Educators, parents, and students should be informed about the benefits, challenges, and ethical considerations.\n",
      "* **Public Engagement:** Engaging the public in discussions about the future of AI in education can help shape policies and practices that align with societal values and priorities.\n",
      "* **Pilot Programs and Research:** Conducting pilot programs and research can provide valuable insights into the effectiveness and impact of AI in education, informing decision-making and addressing concerns.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCounterPointAgent\u001b[0m (to TopicAgent):\n",
      "\n",
      "**Counterpoint:**\n",
      "\n",
      "While AI has the potential to enhance certain aspects of education, it is important to acknowledge its limitations and potential drawbacks:\n",
      "\n",
      "**Lack of Emotional Intelligence:** AI systems lack the emotional intelligence and interpersonal skills inherent in human teachers. They cannot provide the same level of empathy, motivation, and support that is essential for student development and well-being.\n",
      "\n",
      "**Data Bias:** AI algorithms are trained on data, which can reflect existing biases and perpetuate inequalities. This can lead to unfair assessments, biased recommendations, and the marginalization of certain student groups.\n",
      "\n",
      "**Cost and Accessibility:** Implementing AI solutions in education can be expensive, creating a digital divide between those who have access to these technologies and those who do not.\n",
      "\n",
      "**Job Displacement:** The increased use of AI in education may lead to the displacement of some educators, particularly those whose roles can be automated. This could have implications for employment and the livelihoods of many educators.\n",
      "\n",
      "**Over-reliance on Technology:** Relying too heavily on AI can lead to a decreased emphasis on human-to-human interactions and a diminished focus on critical thinking and creativity.\n",
      "\n",
      "**Privacy Concerns:** The collection and analysis of student data by AI systems raises concerns about privacy and surveillance. It is crucial to address these concerns and develop clear guidelines to protect student confidentiality.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mTopicAgent\u001b[0m (to CounterPointAgent):\n",
      "\n",
      "**Rebuttal:**\n",
      "\n",
      "While the counterpoints raised are valid concerns, it is important to consider the following points in rebuttal:\n",
      "\n",
      "**Emotional Intelligence:** While AI systems may not possess the full range of emotional intelligence as humans, they can be designed to provide empathetic and supportive interactions. AI-powered chatbots and virtual assistants can offer emotional support, provide resources, and connect students with human counselors when needed.\n",
      "\n",
      "**Data Bias:** Addressing data bias is a critical challenge in AI development. Researchers and practitioners are actively working on developing techniques to mitigate bias in AI algorithms. By using diverse training data, implementing fairness metrics, and conducting thorough testing, we can reduce the risk of biased outcomes.\n",
      "\n",
      "**Cost and Accessibility:** The cost of AI solutions is decreasing rapidly, and many open-source AI tools and resources are available. Governments and educational institutions can also invest in programs to provide equitable access to AI technologies for all students.\n",
      "\n",
      "**Job Displacement:** While AI may automate certain tasks, it also creates new opportunities for educators. AI can free up educators from repetitive tasks, allowing them to focus on higher-level teaching and provide more personalized support to students. Additionally, AI can empower educators with new tools and insights to enhance their teaching practices.\n",
      "\n",
      "**Over-reliance on Technology:** AI should be used as a tool to complement and enhance human-to-human interactions, not replace them. Educators should carefully consider the appropriate balance of AI and human involvement in different educational contexts. AI can be particularly valuable for tasks such as data analysis, personalized feedback, and adaptive learning, while human educators can focus on fostering creativity, critical thinking, and social-emotional development.\n",
      "\n",
      "**Privacy Concerns:** Robust data privacy and security measures are essential when using AI in education. Governments and educational institutions should develop clear regulations and guidelines to protect student data. Additionally, AI systems can be designed with privacy-preserving techniques, such as anonymization and encryption, to minimize the risk of data misuse.\n",
      "\n",
      "By addressing these concerns and continuing to invest in research and development, we can harness the potential of AI to improve educational outcomes while mitigating its potential drawbacks.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCounterPointAgent\u001b[0m (to TopicAgent):\n",
      "\n",
      "**Counter-Rebuttal:**\n",
      "\n",
      "While the rebuttal addresses some of the concerns raised, it is important to acknowledge the following counter-arguments:\n",
      "\n",
      "**Emotional Intelligence:** AI systems may be able to provide empathetic and supportive interactions to a certain extent, but they cannot fully replicate the human ability to understand and respond to complex emotions, build rapport, and provide personalized guidance.\n",
      "\n",
      "**Data Bias:** Mitigating bias in AI algorithms is an ongoing challenge, and there is no guarantee that it can be completely eliminated. Even with diverse training data and fairness metrics, biases can still persist, leading to unfair or discriminatory outcomes.\n",
      "\n",
      "**Cost and Accessibility:** While the cost of AI solutions may be decreasing, it is still a significant investment for many schools and districts, particularly those with limited resources. Additionally, ensuring equitable access to AI technologies requires not only providing devices and internet connectivity but also addressing the digital literacy gap and providing ongoing support.\n",
      "\n",
      "**Job Displacement:** While AI may create new opportunities for educators, it is important to consider the potential impact on those whose roles are automated. Educators may need to acquire new skills and adapt to changing job requirements, which can be a challenging and stressful process.\n",
      "\n",
      "**Over-reliance on Technology:** Striking the right balance between AI and human involvement is crucial, but it can be difficult to achieve in practice. Educators may be tempted to rely too heavily on AI for tasks that could be better handled by humans, leading to a diminished focus on interpersonal interactions and critical thinking.\n",
      "\n",
      "**Privacy Concerns:** Data privacy and security measures are essential, but they cannot completely eliminate the risk of data misuse. AI systems can still collect and process sensitive student data, raising concerns about surveillance and the potential for data breaches.\n",
      "\n",
      "It is important to proceed cautiously with the adoption of AI in education and to carefully weigh the potential benefits and drawbacks. By addressing these concerns and continuing to engage in thoughtful discussions, we can ensure that AI is used in a responsible and ethical manner to enhance educational outcomes for all students.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mTopicAgent\u001b[0m (to SummaryAgent):\n",
      "\n",
      "AI in education enables personalized learning but may also create challenges.\n",
      "Context: \n",
      "**Additional Points for Discussion:**\n",
      "\n",
      "**Ethical Considerations:**\n",
      "\n",
      "* **Data Privacy:** Ensuring the privacy and security of student data collected and processed by AI systems is paramount. Clear guidelines and regulations are needed to protect student information.\n",
      "* **Algorithmic Transparency:** AI algorithms should be transparent and open to scrutiny to avoid bias and ensure fairness. Educators and students should understand how AI systems make decisions and assess their impact.\n",
      "* **Human Interaction:** AI should complement and enhance human interaction in education, not replace it. Educators play a crucial role in fostering meaningful relationships, providing personalized support, and inspiring students.\n",
      "\n",
      "**Teacher Training and Adoption:**\n",
      "\n",
      "* **Professional Development:** Providing educators with ongoing professional development opportunities is essential for successful AI integration. Training should focus on practical applications, ethical considerations, and data literacy.\n",
      "* **Support Networks:** Establishing support networks and communities of practice can empower educators to share best practices, troubleshoot challenges, and learn from each other's experiences.\n",
      "* **Institutional Support:** Schools and districts should provide resources and infrastructure to support AI adoption, such as access to technology, technical assistance, and dedicated innovation teams.\n",
      "\n",
      "**Future of AI in Education:**\n",
      "\n",
      "* **Personalized Learning at Scale:** AI-powered adaptive learning platforms will become more sophisticated, offering highly personalized learning experiences tailored to each student's unique needs and goals.\n",
      "* **Augmented Reality and Virtual Reality:** AR and VR technologies will enhance educational experiences by providing immersive and interactive learning environments, allowing students to explore complex concepts and simulations.\n",
      "* **Intelligent Tutoring Systems:** AI-powered tutoring systems will provide real-time support and guidance to students, offering personalized feedback and assistance whenever and wherever needed.\n",
      "\n",
      "**Equity and Accessibility:**\n",
      "\n",
      "* **Bridging the Digital Divide:** Ensuring equitable access to AI-powered educational resources is crucial. Initiatives such as providing devices and internet connectivity to underserved communities can help bridge the digital divide.\n",
      "* **Culturally Responsive AI:** AI systems should be culturally responsive and inclusive, representing diverse perspectives and experiences to ensure all students feel seen and valued.\n",
      "* **Universal Design for Learning:** AI can be leveraged to create universally designed learning environments that cater to the needs of all learners, regardless of their abilities or learning styles.\n",
      "\n",
      "**Public Perception and Acceptance:**\n",
      "\n",
      "* **Transparency and Communication:** Open and transparent communication about the use of AI in education is essential for building trust among stakeholders. Educators, parents, and students should be informed about the benefits, challenges, and ethical considerations.\n",
      "* **Public Engagement:** Engaging the public in discussions about the future of AI in education can help shape policies and practices that align with societal values and priorities.\n",
      "* **Pilot Programs and Research:** Conducting pilot programs and research can provide valuable insights into the effectiveness and impact of AI in education, informing decision-making and addressing concerns.\n",
      "**Counter-Rebuttal:**\n",
      "\n",
      "While the rebuttal addresses some of the concerns raised, it is important to acknowledge the following counter-arguments:\n",
      "\n",
      "**Emotional Intelligence:** AI systems may be able to provide empathetic and supportive interactions to a certain extent, but they cannot fully replicate the human ability to understand and respond to complex emotions, build rapport, and provide personalized guidance.\n",
      "\n",
      "**Data Bias:** Mitigating bias in AI algorithms is an ongoing challenge, and there is no guarantee that it can be completely eliminated. Even with diverse training data and fairness metrics, biases can still persist, leading to unfair or discriminatory outcomes.\n",
      "\n",
      "**Cost and Accessibility:** While the cost of AI solutions may be decreasing, it is still a significant investment for many schools and districts, particularly those with limited resources. Additionally, ensuring equitable access to AI technologies requires not only providing devices and internet connectivity but also addressing the digital literacy gap and providing ongoing support.\n",
      "\n",
      "**Job Displacement:** While AI may create new opportunities for educators, it is important to consider the potential impact on those whose roles are automated. Educators may need to acquire new skills and adapt to changing job requirements, which can be a challenging and stressful process.\n",
      "\n",
      "**Over-reliance on Technology:** Striking the right balance between AI and human involvement is crucial, but it can be difficult to achieve in practice. Educators may be tempted to rely too heavily on AI for tasks that could be better handled by humans, leading to a diminished focus on interpersonal interactions and critical thinking.\n",
      "\n",
      "**Privacy Concerns:** Data privacy and security measures are essential, but they cannot completely eliminate the risk of data misuse. AI systems can still collect and process sensitive student data, raising concerns about surveillance and the potential for data breaches.\n",
      "\n",
      "It is important to proceed cautiously with the adoption of AI in education and to carefully weigh the potential benefits and drawbacks. By addressing these concerns and continuing to engage in thoughtful discussions, we can ensure that AI is used in a responsible and ethical manner to enhance educational outcomes for all students.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mSummaryAgent\u001b[0m (to TopicAgent):\n",
      "\n",
      "AI in education offers personalized learning but presents ethical and practical challenges, such as data privacy, algorithmic transparency, teacher training, and equity. Future advancements include personalized learning at scale, AR/VR experiences, and intelligent tutoring systems. Addressing concerns about emotional intelligence, data bias, cost, job displacement, over-reliance on technology, and privacy is crucial for responsible AI adoption. Ongoing discussions and pilot programs can shape policies and ensure AI enhances education for all students.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mTopicAgent\u001b[0m (to SummaryAgent):\n",
      "\n",
      "**Summary of AI in Education Discussion:**\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "* AI offers personalized learning experiences but presents ethical and practical challenges.\n",
      "* Ethical considerations include data privacy, algorithmic transparency, and human interaction.\n",
      "* Successful AI integration requires teacher training, adoption, and institutional support.\n",
      "* Future advancements include personalized learning at scale, AR/VR experiences, and intelligent tutoring systems.\n",
      "* Equity and accessibility are crucial, addressing the digital divide and ensuring culturally responsive AI.\n",
      "\n",
      "**Counter-Arguments and Mitigation Strategies:**\n",
      "\n",
      "* **Emotional Intelligence:** AI systems can provide empathetic interactions and support, but ongoing research is needed to enhance their ability to understand and respond to complex emotions.\n",
      "* **Data Bias:** Mitigating bias in AI algorithms is an ongoing challenge, requiring diverse training data, fairness metrics, and human oversight to minimize discriminatory outcomes.\n",
      "* **Cost and Accessibility:** Addressing cost and accessibility involves providing devices, internet connectivity, digital literacy training, and ongoing support, particularly for underserved communities.\n",
      "* **Job Displacement:** Educators need to acquire new skills and adapt to changing job requirements, with support from professional development and retraining programs.\n",
      "* **Over-reliance on Technology:** Striking a balance between AI and human involvement is crucial, with educators focusing on interpersonal interactions and critical thinking alongside AI-powered tasks.\n",
      "* **Privacy Concerns:** Implementing robust data privacy and security measures, obtaining informed consent, and limiting data collection to essential purposes can mitigate privacy risks.\n",
      "\n",
      "**Moving Forward:**\n",
      "\n",
      "* Ongoing discussions and pilot programs can inform decision-making and shape policies for responsible AI adoption.\n",
      "* Public engagement, transparency, and communication are vital for building trust and addressing concerns.\n",
      "* Continued research and innovation will drive advancements in AI-powered educational tools and practices.\n",
      "* By carefully considering the benefits and drawbacks and addressing ethical and practical challenges, AI can be harnessed to enhance educational outcomes and create a more equitable and personalized learning experience for all students.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mSummaryAgent\u001b[0m (to TopicAgent):\n",
      "\n",
      "**Summary of AI in Education Discussion:**\n",
      "\n",
      "AI in education offers personalized learning experiences but presents ethical and practical challenges. Successful AI integration requires addressing concerns about data privacy, algorithmic transparency, teacher training, equity, and accessibility. While counter-arguments exist regarding emotional intelligence, data bias, cost, job displacement, over-reliance on technology, and privacy, mitigation strategies can minimize these concerns. Ongoing discussions, pilot programs, public engagement, and research are crucial for shaping responsible AI adoption policies. By carefully considering the benefits and drawbacks, AI can enhance educational outcomes and create a more equitable and personalized learning experience for all students.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Conversational agents\n",
    "topic_agent = ConversableAgent(\n",
    "    name=\"TopicAgent\",\n",
    "    system_message=\"You start a conversation by introducing a topic for discussion.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "insight_agent = ConversableAgent(\n",
    "    name=\"InsightAgent\",\n",
    "    system_message=\"You provide an interesting insight or background information on the topic introduced.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "counterpoint_agent = ConversableAgent(\n",
    "    name=\"CounterPointAgent\",\n",
    "    system_message=\"You provide a counterpoint or a differing perspective on the topic being discussed.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "summary_agent = ConversableAgent(\n",
    "    name=\"SummaryAgent\",\n",
    "    system_message=\"You summarize the entire discussion in a concise manner.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Start a sequence of conversational chats\n",
    "chat_results = topic_agent.initiate_chats(\n",
    "    [\n",
    "        {\n",
    "            \"recipient\": insight_agent,\n",
    "            \"message\": \"Let's discuss the impact of AI on education.\",\n",
    "            \"max_turns\": 2,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": counterpoint_agent,\n",
    "            \"message\": \"AI's role in education is transforming the way students learn.\",\n",
    "            \"max_turns\": 2,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": summary_agent,\n",
    "            \"message\": \"AI in education enables personalized learning but may also create challenges.\",\n",
    "            \"max_turns\": 2,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# # Print summaries for each chat\n",
    "# print(\"First Chat Summary (Insight):\", chat_results[0].summary)\n",
    "# print(\"Second Chat Summary (Counterpoint):\", chat_results[1].summary)\n",
    "# print(\"Third Chat Summary (Summary):\", chat_results[2].summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogen-agentchat~=0.2 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (0.2.40)\n",
      "Requirement already satisfied: diskcache in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from autogen-agentchat~=0.2) (5.6.3)\n",
      "Requirement already satisfied: docker in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from autogen-agentchat~=0.2) (7.1.0)\n",
      "Requirement already satisfied: flaml in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from autogen-agentchat~=0.2) (2.3.3)\n",
      "Requirement already satisfied: numpy<2,>=1.17.0 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from autogen-agentchat~=0.2) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.3 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from autogen-agentchat~=0.2) (1.58.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from autogen-agentchat~=0.2) (24.2)\n",
      "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from autogen-agentchat~=0.2) (2.10.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from autogen-agentchat~=0.2) (1.0.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from autogen-agentchat~=0.2) (2.5.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from autogen-agentchat~=0.2) (0.8.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from openai>=1.3->autogen-agentchat~=0.2) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from openai>=1.3->autogen-agentchat~=0.2) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from openai>=1.3->autogen-agentchat~=0.2) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from openai>=1.3->autogen-agentchat~=0.2) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from openai>=1.3->autogen-agentchat~=0.2) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from openai>=1.3->autogen-agentchat~=0.2) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from openai>=1.3->autogen-agentchat~=0.2) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from pydantic!=2.6.0,<3,>=1.10->autogen-agentchat~=0.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from pydantic!=2.6.0,<3,>=1.10->autogen-agentchat~=0.2) (2.27.1)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from docker->autogen-agentchat~=0.2) (308)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from docker->autogen-agentchat~=0.2) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from docker->autogen-agentchat~=0.2) (2.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from tiktoken->autogen-agentchat~=0.2) (2024.11.6)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5,>=3.5.0->openai>=1.3->autogen-agentchat~=0.2) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->openai>=1.3->autogen-agentchat~=0.2) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->openai>=1.3->autogen-agentchat~=0.2) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->autogen-agentchat~=0.2) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.26.0->docker->autogen-agentchat~=0.2) (3.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\arulm\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai>=1.3->autogen-agentchat~=0.2) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install autogen-agentchat~=0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list=[\n",
    "    {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"api_key\": \"####\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first define the assistant agent that suggests tool calls.\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"Apex Coder\",\n",
    "    llm_config={ \n",
    "                \"cache_seed\":41,\n",
    "                \"config_list\":config_list,\n",
    "                \"temperature\":0,\n",
    "                \n",
    "                },\n",
    "    description=\"An assistant whose job is only to generate code in Apex programming language for Salesforce development tasks and does not have the capability to execute the code Once proper code is generated return in apex code block\",\n",
    "    )\n",
    "\n",
    "# Configure the UserProxyAgent for Apex-specific tasks\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    code_execution_config={\"use_docker\":False},\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to Apex Coder):\n",
      "\n",
      "Write an Apex class to calculate the compound interest wrap the generated apex code within '''apex''' code block Ensure it includes proper documentation and a test method.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mApex Coder\u001b[0m (to user_proxy):\n",
      "\n",
      "Sure, here is an Apex class that calculates the compound interest. It includes a method `calculateCompoundInterest` that takes principal amount, rate of interest, and number of years as parameters to calculate the compound interest. It also includes a test method `testCalculateCompoundInterest` to test the functionality.\n",
      "\n",
      "```apex\n",
      "/**\n",
      " * CompoundInterestCalculator Class\n",
      " * This class provides a method to calculate the compound interest.\n",
      " */\n",
      "public class CompoundInterestCalculator {\n",
      "    /**\n",
      "     * calculateCompoundInterest Method\n",
      "     * This method calculates the compound interest based on the provided principal amount, rate of interest, and number of years.\n",
      "     *\n",
      "     * @param principal The principal amount\n",
      "     * @param rate The rate of interest\n",
      "     * @param years The number of years\n",
      "     * @return The calculated compound interest\n",
      "     */\n",
      "    public static Decimal calculateCompoundInterest(Decimal principal, Decimal rate, Integer years) {\n",
      "        Decimal amount = principal * Math.pow((1 + rate / 100), years);\n",
      "        Decimal compoundInterest = amount - principal;\n",
      "        return compoundInterest;\n",
      "    }\n",
      "}\n",
      "\n",
      "/**\n",
      " * CompoundInterestCalculatorTest Class\n",
      " * This class provides a test method to test the calculateCompoundInterest method of the CompoundInterestCalculator class.\n",
      " */\n",
      "@isTest\n",
      "private class CompoundInterestCalculatorTest {\n",
      "    /**\n",
      "     * testCalculateCompoundInterest Method\n",
      "     * This method tests the calculateCompoundInterest method of the CompoundInterestCalculator class.\n",
      "     */\n",
      "    static testMethod void testCalculateCompoundInterest() {\n",
      "        Decimal principal = 10000;\n",
      "        Decimal rate = 5;\n",
      "        Integer years = 5;\n",
      "        Decimal expectedCompoundInterest = 2762.82;\n",
      "        Decimal actualCompoundInterest = CompoundInterestCalculator.calculateCompoundInterest(principal, rate, years);\n",
      "        System.assertEquals(expectedCompoundInterest, actualCompoundInterest, 'The calculated compound interest is not correct.');\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "Please note that the `calculateCompoundInterest` method uses the formula for compound interest: A = P(1 + r/n)^(nt), where:\n",
      "- A is the amount of money accumulated after n years, including interest.\n",
      "- P is the principal amount (the initial amount of money).\n",
      "- r is the annual interest rate (in decimal).\n",
      "- n is the number of times that interest is compounded per year.\n",
      "- t is the number of years the money is invested for.\n",
      "\n",
      "In this case, we assume that the interest is compounded once per year, so n is 1.\n",
      "\n",
      "The test method `testCalculateCompoundInterest` tests the `calculateCompoundInterest` method with a principal amount of 10000, a rate of interest of 5%, and a period of 5 years. The expected compound interest is calculated manually and used to assert the correctness of the `calculateCompoundInterest` method.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is apex)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to Apex Coder):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "unknown language apex\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid 'messages[2].name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': 'messages[2].name', 'code': 'invalid_value'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m chat_res \u001b[38;5;241m=\u001b[39m \u001b[43muser_proxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43massistant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mWrite an Apex class to calculate the compound interest wrap the generated apex code within \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mapex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m code block Ensure it includes proper documentation and a test method.\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msummary_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreflection_with_llm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\autogen\\agentchat\\conversable_agent.py:1153\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1152\u001b[0m         msg2send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_init_message(message, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1154\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summarize_chat(\n\u001b[0;32m   1155\u001b[0m     summary_method,\n\u001b[0;32m   1156\u001b[0m     summary_args,\n\u001b[0;32m   1157\u001b[0m     recipient,\n\u001b[0;32m   1158\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[0;32m   1159\u001b[0m )\n\u001b[0;32m   1160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\autogen\\agentchat\\conversable_agent.py:788\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    786\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient, is_sending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m--> 788\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    792\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\autogen\\agentchat\\conversable_agent.py:955\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    953\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_reply(messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_messages[sender], sender\u001b[38;5;241m=\u001b[39msender)\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 955\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\autogen\\agentchat\\conversable_agent.py:788\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    786\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient, is_sending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m--> 788\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    792\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\autogen\\agentchat\\conversable_agent.py:955\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    953\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_reply(messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_messages[sender], sender\u001b[38;5;241m=\u001b[39msender)\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 955\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\autogen\\agentchat\\conversable_agent.py:788\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    786\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient, is_sending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m--> 788\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    792\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\autogen\\agentchat\\conversable_agent.py:953\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 953\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\autogen\\agentchat\\conversable_agent.py:2113\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[0;32m   2111\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   2112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[1;32m-> 2113\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[0;32m   2115\u001b[0m         log_event(\n\u001b[0;32m   2116\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2117\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2121\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[0;32m   2122\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\autogen\\agentchat\\conversable_agent.py:1475\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m   1473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m messages \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1474\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_oai_messages[sender]\n\u001b[1;32m-> 1475\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_oai_reply_from_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_oai_system_message\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_cache\u001b[49m\n\u001b[0;32m   1477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, extracted_response)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\autogen\\agentchat\\conversable_agent.py:1494\u001b[0m, in \u001b[0;36mConversableAgent._generate_oai_reply_from_client\u001b[1;34m(self, llm_client, messages, cache)\u001b[0m\n\u001b[0;32m   1491\u001b[0m         all_messages\u001b[38;5;241m.\u001b[39mappend(message)\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;66;03m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[1;32m-> 1494\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1500\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m llm_client\u001b[38;5;241m.\u001b[39mextract_text_or_completion_object(response)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\autogen\\oai\\client.py:869\u001b[0m, in \u001b[0;36mOpenAIWrapper.create\u001b[1;34m(self, **config)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    868\u001b[0m     request_ts \u001b[38;5;241m=\u001b[39m get_current_ts()\n\u001b[1;32m--> 869\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m APITimeoutError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    871\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\autogen\\oai\\client.py:423\u001b[0m, in \u001b[0;36mOpenAIClient.create\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    421\u001b[0m     params \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    422\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 423\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_or_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_utils\\_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\resources\\chat\\completions.py:859\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    856\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    857\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    858\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1279\u001b[0m     )\n\u001b[1;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1070\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Invalid 'messages[2].name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': 'messages[2].name', 'code': 'invalid_value'}}"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "chat_res = user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"Write an Apex class to calculate the compound interest wrap the generated apex code within '''apex''' code block Ensure it includes proper documentation and a test method.\"\"\",\n",
    "    summary_method=\"reflection_with_llm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
